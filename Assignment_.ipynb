{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5/1MgSpq9CwiPfyLvCvvl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junoso/AndroidQuizApp/blob/main/Assignment_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. SETUP -------------------------------------------------\n",
        "!pip install -q tensorflow opencv-python-headless scikit-learn pandas matplotlib\n",
        "\n",
        "import os, cv2, numpy as np, json, shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "print(f\"TF: {tf.__version__} | GPU: {tf.config.list_physical_devices('GPU')}\")\n",
        "\n",
        "# --- 2. DOWNLOAD FULL DATASET ---------------------------------\n",
        "!git clone https://github.com/chenkenanalytic/handwritting_data_all.git\n",
        "%cd handwritting_data_all\n",
        "!cat all_data.zip* > all_data.zip\n",
        "!unzip -q all_data.zip -d extracted_data\n",
        "DATA_DIR = \"/content/handwritting_data_all/extracted_data/cleaned_data\"\n"
      ],
      "metadata": {
        "id": "ne4dEmGh9_EX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c9968bd-8267-4464-a113-a4f097e2dd50"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF: 2.19.0 | GPU: []\n",
            "fatal: destination path 'handwritting_data_all' already exists and is not an empty directory.\n",
            "/content/handwritting_data_all\n",
            "replace extracted_data/cleaned_data/10000/ф═_0.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace extracted_data/cleaned_data/10000/ф═_1.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace extracted_data/cleaned_data/10000/ф═_10.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace extracted_data/cleaned_data/10000/ф═_11.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace extracted_data/cleaned_data/10000/ф═_12.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace extracted_data/cleaned_data/10000/ф═_13.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace extracted_data/cleaned_data/10000/ф═_14.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace extracted_data/cleaned_data/10000/ф═_15.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace extracted_data/cleaned_data/10000/ф═_16.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace extracted_data/cleaned_data/10000/ф═_17.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace extracted_data/cleaned_data/10000/ф═_18.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace extracted_data/cleaned_data/10000/ф═_19.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace extracted_data/cleaned_data/10000/ф═_2.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace extracted_data/cleaned_data/10000/ф═_20.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace extracted_data/cleaned_data/10000/ф═_21.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace extracted_data/cleaned_data/10000/ф═_22.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace extracted_data/cleaned_data/10000/ф═_23.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace extracted_data/cleaned_data/10000/ф═_24.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace extracted_data/cleaned_data/10000/ф═_25.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace extracted_data/cleaned_data/10000/ф═_26.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace extracted_data/cleaned_data/10000/ф═_26.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyWfZoZB72P2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abbafc0c-bf5b-41c4-e06b-deffdf6d6b7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Characters: 13065\n",
            "Train raw: 444040 | Test: 111010\n"
          ]
        }
      ],
      "source": [
        "# --------------------------------------------------------------\n",
        "# 3. GROUP BY CHARACTER\n",
        "# --------------------------------------------------------------\n",
        "char_images = {}\n",
        "for root, _, files in os.walk(DATA_DIR):\n",
        "    for f in files:\n",
        "        if f.lower().endswith('.png'):\n",
        "            char = os.path.basename(root)\n",
        "            char_images.setdefault(char, []).append(os.path.join(root, f))\n",
        "\n",
        "print(f\"Characters: {len(char_images)}\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 4. TRAIN / TEST SPLIT (first 40 → train)\n",
        "# --------------------------------------------------------------\n",
        "train_paths, train_labels = [], []\n",
        "test_paths,  test_labels  = [], []\n",
        "\n",
        "for char, imgs in char_images.items():\n",
        "    imgs = sorted(imgs)\n",
        "    if len(imgs) < 50: continue\n",
        "    train_paths.extend(imgs[:40])\n",
        "    train_labels.extend([char]*40)\n",
        "    test_paths.extend(imgs[40:50])\n",
        "    test_labels.extend([char]*len(imgs[40:50]))\n",
        "\n",
        "print(f\"Train raw: {len(train_paths)} | Test: {len(test_paths)}\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 5. AUGMENTATION (OpenCV)\n",
        "# --------------------------------------------------------------\n",
        "def augment_image(img):\n",
        "    h, w = img.shape[:2]\n",
        "    Ms = [\n",
        "        cv2.getRotationMatrix2D((w/2, h/2),  5, 1.0),\n",
        "        cv2.getRotationMatrix2D((w/2, h/2), -5, 1.0),\n",
        "        cv2.getRotationMatrix2D((w/2, h/2),  0, 1.1),\n",
        "        cv2.getRotationMatrix2D((w/2, h/2),  0, 0.9),\n",
        "        np.float32([[1, 0.1, 0], [0, 1, 0]])\n",
        "    ]\n",
        "    return [cv2.warpAffine(img, M, (w, h),\n",
        "                           borderMode=cv2.BORDER_CONSTANT,\n",
        "                           borderValue=255) for M in Ms]\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 6. LOAD + RESIZE (64×64)\n",
        "# --------------------------------------------------------------\n",
        "IMG_SIZE = 64\n",
        "\n",
        "def load(path, augment=False):\n",
        "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "    img = img.astype('float32')/255.0\n",
        "    img = np.expand_dims(img, -1)\n",
        "    if augment:\n",
        "        return augment_image(img)\n",
        "    return [img]\n",
        "\n",
        "# TRAIN (with augmentation)\n",
        "X_train, y_train = [], []\n",
        "for p, l in zip(train_paths, train_labels):\n",
        "    imgs = load(p, augment=True)\n",
        "    X_train.extend(imgs)\n",
        "    y_train.extend([l]*len(imgs))\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "# TEST (no augmentation)\n",
        "X_test, y_test = [], []\n",
        "for p, l in zip(test_paths, test_labels):\n",
        "    X_test.append(load(p, augment=False)[0])\n",
        "    y_test.append(l)\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "print(f\"Train (aug): {X_train.shape} | Test: {X_test.shape}\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 7. LABEL ENCODING\n",
        "# --------------------------------------------------------------\n",
        "le = LabelEncoder()\n",
        "y_train_enc = le.fit_transform(y_train)\n",
        "y_test_enc  = le.transform(y_test)\n",
        "num_classes = len(le.classes_)\n",
        "print(f\"Classes: {num_classes}\")\n",
        "\n",
        "with open(\"/content/label_map.json\",\"w\",encoding=\"utf-8\") as f:\n",
        "    json.dump({i:c for i,c in enumerate(le.classes_)}, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 8. VISUALIZE ORIGINAL + AUGMENTED\n",
        "# --------------------------------------------------------------\n",
        "sample = cv2.imread(train_paths[0],0)\n",
        "sample = cv2.resize(sample,(64,64))\n",
        "aug = augment_image(sample)[:4]\n",
        "\n",
        "plt.figure(figsize=(10,2))\n",
        "imgs = [sample] + aug\n",
        "titles = ['Original','+5°','-5°','1.1×','0.9×']\n",
        "for i,im in enumerate(imgs):\n",
        "    plt.subplot(1,5,i+1); plt.imshow(im,cmap='gray'); plt.title(titles[i]); plt.axis('off')\n",
        "plt.suptitle(f\"Character: {train_labels[0]}\")\n",
        "plt.show()\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 9. MODELS\n",
        "# --------------------------------------------------------------\n",
        "def baseline_cnn():\n",
        "    m = keras.Sequential([\n",
        "        keras.layers.Conv2D(32,(5,5),activation='relu',input_shape=(64,64,1)),\n",
        "        keras.layers.MaxPooling2D((2,2)),\n",
        "        keras.layers.Dropout(0.2),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(128,activation='relu'),\n",
        "        keras.layers.Dense(num_classes,activation='softmax')\n",
        "    ])\n",
        "    m.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "    return m\n",
        "\n",
        "def deeper_cnn():\n",
        "    m = keras.Sequential([\n",
        "        keras.layers.Conv2D(32,(5,5),activation='relu',input_shape=(64,64,1)),\n",
        "        keras.layers.MaxPooling2D((2,2)),\n",
        "        keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "        keras.layers.MaxPooling2D((2,2)),\n",
        "        keras.layers.Dropout(0.2),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(256,activation='relu'),\n",
        "        keras.layers.Dense(128,activation='relu'),\n",
        "        keras.layers.Dense(num_classes,activation='softmax')\n",
        "    ])\n",
        "    m.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "    return m\n",
        "\n",
        "def larger_cnn():\n",
        "    m = keras.Sequential([\n",
        "        keras.layers.Conv2D(30,(5,5),activation='relu',input_shape=(64,64,1)),\n",
        "        keras.layers.MaxPooling2D((2,2)),\n",
        "        keras.layers.Conv2D(15,(3,3),activation='relu'),\n",
        "        keras.layers.MaxPooling2D((2,2)),\n",
        "        keras.layers.Dropout(0.2),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(128,activation='relu'),\n",
        "        keras.layers.Dense(50,activation='relu'),\n",
        "        keras.layers.Dense(num_classes,activation='softmax')\n",
        "    ])\n",
        "    m.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "    return m\n",
        "\n",
        "models = [(\"Baseline CNN\",baseline_cnn),\n",
        "          (\"Deeper CNN\",deeper_cnn),\n",
        "          (\"Larger CNN\",larger_cnn)]\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 10. TRAIN & EVALUATE\n",
        "# --------------------------------------------------------------\n",
        "results = []\n",
        "for name, fn in models:\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    model = fn()\n",
        "    model.fit(X_train, y_train_enc,\n",
        "              validation_data=(X_test, y_test_enc),\n",
        "              epochs=10, batch_size=128, verbose=1)\n",
        "    loss, acc = model.evaluate(X_test, y_test_enc, verbose=0)\n",
        "    results.append({\"Model\":name, \"Test Accuracy\":f\"{acc:.4f}\"})\n",
        "    model.save(f\"/content/model_{name.replace(' ','_')}.h5\")\n",
        "    print(f\"{name} → {acc:.4%}\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 11. RESULT TABLE\n",
        "# --------------------------------------------------------------\n",
        "df_results = pd.DataFrame(results)\n",
        "display(Markdown(\"### Model Comparison\"))\n",
        "display(df_results)\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 12. BUILD GITHUB REPO FOLDER\n",
        "# --------------------------------------------------------------\n",
        "!mkdir -p /content/DIT5411-HoYiTik\n",
        "!cp /content/model_*.h5 /content/DIT5411-HoYiTik/ 2>/dev/null || true\n",
        "!cp /content/label_map.json /content/DIT5411-HoYiTik/\n",
        "!mkdir -p /content/DIT5411-HoYiTik/sample_images\n",
        "!cp {train_paths[0]} /content/DIT5411-HoYiTik/sample_images/original.png\n",
        "\n"
      ]
    }
  ]
}